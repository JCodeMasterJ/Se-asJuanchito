
# Detecci칩n del Lenguaje de Se침as Colombiano (LSC)

Este proyecto tiene como objetivo **reconocer palabras formadas por se침as del Lenguaje de Se침as Colombiano (LSC)** a partir de gestos realizados con la mano frente a una c치mara, usando t칠cnicas de Machine Learning (ML) y visi칩n por computador.

<p align="center">
  <img src="https://github.com/user-attachments/assets/8b76c331-2e7c-40f0-a50e-9afc9528edbe" width="600"/>
</p>

---

## Descripci칩n General del Dataset

Se desarroll칩 un modelo de **clasificaci칩n de im치genes entrenado en Google Colab**, utilizando dos fuentes principales de datos:

- Un **dataset propio**, creado por los estudiantes de la asignatura electiva Python de la Universidad Santo Tom치s.
- Un **dataset de acceso abierto** proporcionado por la **Universidad del Cauca**, disponible en el siguiente DOI:  
  游댕 [https://doi.org/10.1016/j.dib.2024.111213](https://doi.org/10.1016/j.dib.2024.111213)

El dataset complementario de la Universidad del Cauca cuenta con m치s de **400 im치genes por cada letra**, lo que permiti칩 **reforzar y mejorar el rendimiento del modelo** entrenado. Cabe resaltar que ambos datasets incluyen 칰nicamente **gestos est치ticos** del alfabeto en LSC (por lo tanto, no se incluyen letras como "J" o "H" que requieren movimiento).

### Caracter칤sticas del dataset

- Se aprovech칩 el curso gratuito de **Academy Edutin** para aprender sobre el Lenguaje de Se침as Colombiano (LSC) y se incorporaron se침as adicionales como **"rr"**, que forma parte del abecedario en LSC.
- Todas las im치genes tienen un tama침o de **640x480 p칤xeles**.
- Para el **dataset est치tico**:
  - Se aplicaron t칠cnicas de **data augmentation** para aumentar la variabilidad y robustez de los datos.
  - A cada imagen se le extrajeron **21 puntos landmarks** por mano (coordenadas **x, y, z**), generando un **vector de 63 valores**.

---

### Visualizaci칩n de los datasets

**Dataset propio de los estudiantes de la electiva Python:**  
<p align="center">
  <img src="https://github.com/user-attachments/assets/64a581f5-67d1-4857-80a4-c45fc87a87bc" width="600"/>
</p>

**Dataset Universidad del Cauca:**  
<p align="center">
  <img src="https://github.com/user-attachments/assets/24083207-d1c2-4437-991a-f8b1d277ba3c" width="600"/>
</p>

---

##  Tecnolog칤as utilizadas

- Google Colab
- Python (Anaconda / Spyder)
- TensorFlow / Keras
- MediaPipe Hands
- OpenCV

---

##  Proceso de desarrollo

1. **Limpieza y organizaci칩n del dataset.**
2. **Extracci칩n de caracter칤sticas (landmarks)** de las manos utilizando MediaPipe, guardando las coordenadas en un archivo `.csv`.
3. **Entrenamiento del modelo de clasificaci칩n** en Google Colab a partir de los valores num칠ricos del `.csv`, representando los puntos clave de la mano en cada imagen.
4. **Exportaci칩n del modelo entrenado (.h5)** y carga en el entorno de desarrollo Spyder (Anaconda).
5. Programaci칩n del script (python) para la **detecci칩n de landmarks en tiempo real** mediante MediaPipe para generar palabras.
6. **Clasificaci칩n en tiempo real desde la c치mara**, utilizando el modelo previamente entrenado.

---
## Entrenamiento del Modelo

El modelo fue entrenado utilizando un **archivo `.csv`**, el cual conten칤a la relacion entre:

- Las im치genes del dataset.
- Los **landmarks** (puntos cr칤ticos de la mano) extra칤dos con MediaPipe, representados mediante sus coordenadas **x, y, z**.

### Arquitectura del modelo

Se utiliz칩 un modelo **secuencial** con la siguiente estructura:

- **Capa de entrada**: recibe los vectores de 63 caracter칤sticas (21 puntos * 3 coordenadas).
- **Dos capas ocultas**: capas densas (fully connected) con funciones de activaci칩n `ReLU`.
- **Capa de salida**: capa densa con funci칩n de activaci칩n `Softmax`, para la clasificaci칩n multiclase de las letras.

### Resultados

- El modelo alcanz칩 un **70% de precisi칩n** en el conjunto de validaci칩n.
- El entrenamiento fue realizado en **Google Colab**, optimizando la funci칩n de p칠rdida `categorical_crossentropy` con el optimizador `Adam`.

---

### Gr치fica de Precisi칩n del Modelo


*A continuaci칩n se muestra la gr치fica de la evoluci칩n de la precisi칩n durante el entrenamiento:*

<p align="center">
  <img src="https://github.com/user-attachments/assets/4a2629af-9e0d-442e-8e9b-35563d2bf843" width="500"/>
</p>

## Resultados

En la aplicaci칩n programada en Python (utilizando Spyder) se integr칩 el modelo entrenado para el reconocimiento de se침as. Es importante destacar que el modelo original fue entrenado 칰nicamente con **letras est치ticas** del alfabeto en LSC.

Las **letras din치micas** (como "J" o "H") fueron implementadas posteriormente mediante **funciones adicionales en Python**, aprovechando el an치lisis de **secuencias de landmarks** detectados en tiempo real con MediaPipe.

El funcionamiento general de la aplicaci칩n se basa en un **sistema de captura de im치genes en secuencia**, que permite:

- Detectar si la se침a corresponde a una **letra est치tica** (clasificada por el modelo) o a una **letra din치mica** (detectada por las funciones personalizadas de an치lisis de movimiento).
- Escribir palabras letra por letra conforme se reconocen las se침as frente a la c치mara.
- Utilizar un **modo din치mico** y un **modo est치tico** de forma independiente, optimizando as칤 la precisi칩n de reconocimiento en cada caso.
- Incorporar **funciones especiales mediante teclas de control** para gestionar la ejecuci칩n:
  
  - **d**: iniciar la detecci칩n.
  - **r**: reiniciar la palabra escrita.
  - **p**: pausar el reconocimiento.
  - **q**: cerrar la c치mara y terminar la aplicaci칩n.

---

### Captura de la aplicaci칩n en ejecuci칩n

*A continuaci칩n se muestra una imagen de la aplicaci칩n corriendo en Spyder:*

<p align="center">
  <img src="https://github.com/user-attachments/assets/63d16c5f-c1b9-4be5-a2d1-1823d7fa99d6" width="600"/>
</p>

---

##  Recomendaciones de Uso

Para garantizar un funcionamiento 칩ptimo de la aplicaci칩n, se sugiere tener en cuenta las siguientes recomendaciones:

-  **Iluminaci칩n adecuada**: utiliza el sistema en un entorno bien iluminado y con fondo neutro para mejorar la detecci칩n de los landmarks de la mano.
-  **Evitar accesorios**: no usar anillos, relojes u otros objetos que puedan interferir con el reconocimiento de la mano.
-  **Velocidad de captura**: la aplicaci칩n opera a **3 FPS** (frames por segundo) para mantener un equilibrio entre precisi칩n y rendimiento. Aumentar esta tasa puede provocar ralentizaci칩n del video en tiempo real.
-  **Distancia a la c치mara**: mant칠n una distancia estable y visible frente a la c치mara; se recomienda entre 40 cm y 80 cm.
-  **Uso separado de modos**: aunque el sistema permite mezclar letras est치ticas y din치micas, se recomienda utilizar **modo din치mico o modo est치tico por separado** para obtener mejores resultados.
   **No cerrar la app forzadamente**: utilizar la tecla **q** para cerrar la c치mara correctamente y evitar conflictos en procesos posteriores.

---

Con estas buenas pr치cticas, el sistema puede lograr una mayor precisi칩n. Se espera que en caso de ser utilizado pueda ser muy 칰til para futuros proyectos.

